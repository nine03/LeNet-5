# LeNet-5

### 开发环境(Development Environment 개발환경)
- PyCharm
- Python
- Torch

### 发展背景和基本概念

卷积神经网络（Convolutional Neural Network，CNN）是一种前馈型的神经网络，其在大型图像处理方面有出色的表现，目前已经被大范围使用到图像分类、定位等领域中。相比于其他神经网络结构，卷积神经网络需要的参数相对较少，使的其能够广泛应用。

 卷积神经网络是目前深度学习技术领域中非常具有代表性的神经网络之一，在图像分析和处理领域取得了众多突破性的进展，在学术界常用的标准图像标注集ImageNet上，基于卷积神经网络取得了很多成就，包括图像特征提取分类、场景识别等。卷积神经网络相较于传统的图像处理算法的优点之一在于避免了对图像复杂的前期预处理过程，尤其是人工参与图像预处理过程，卷积神经网络可以直接输入原始图像进行一系列工作，至今己经广泛应用于各类图像相关的应用中。
       从卷积神经网络的提出到目前的广泛应用，大致经历了理论萌芽阶段、实验发展阶段以及大规模应用和深入研究阶段。
（1）理论萌芽阶段。1962年Hubel以及Wiesel通过生物学研究表明，从视网膜传递脑中的视觉信息是通过多层次的感受野（Receptive Field）激发完成的，并首先提出了感受野的概念。1980年日本学者Fukushima在基于感受野的概念基础之上，提出了神经认知机(Neocognitron)。神经认知机是一个自组织的多层神经网络模型，每一层的响应都由上一层的局部感受野激发得到，对于模式的识别不受位置、较小形状变化以及尺度大小的影响。神经认知机可以理解为卷积神经网络的第一版，核心点在于将视觉系统模型化，并且不受视觉中的位置和大小等影响。 

（2）实验发展阶段。1998年计算机科学家Yann LeCun等提出的LeNet5采用了基于梯度的反向传播算法对网络进行有监督的训练，Yann LeCun在机器学习、计算机视觉等都有杰出贡献，被誉为卷积神经网络之父。LeNet5网络通过交替连接的卷积层和下采样层，将原始图像逐渐转换为一系列的特征图，并且将这些特征传递给全连接的神经网络，以根据图像的特征对图像进行分类。感受野是卷积神经网络的核心，卷积神经网络的卷积核则是感受野概念的结构表现。学术界对于卷积神经网络的关注，也正是开始于LeNet5网络的提出，并成功应用于手写体识别。同时，卷积神经网络在语音识别、物体检测、人脸识别等应用领域的研究也逐渐开展起来。
（3）大规模应用和深入研究阶段。在LeNet5网络之后，卷积神经网络一直处于实验发展阶段。直到2012年AlexNet网络的提出才奠定了卷积神经网络在深度学习应用中的地位，Krizhevsky（他是hintion的学生对应的论文就是刚开始提到的深度卷积神经网络）等提出的卷积神经网络AlexNet在ImageNet的训练集上取得了图像分类的冠军，使得卷积神经网络成为计算机视觉中的重点研究对象，并且不断深入。在AlexNet之后，不断有新的卷积神经网络提出，包括牛津大学的VGG网络、微软的ResNet网络、谷歌的GoogLeNet网络等，这些网络的提出使得卷积神经网络逐步开始走向商业化应用，几乎只要是存在图像的地方，就会有卷积神经网络的身影。
       从目前的发展趋势而言，卷积神经网络将依然会持续发展，并且会产生适合各类应用场景的卷积神经网络，例如，面向视频理解的3D卷积神经网络等。值得说明的是，卷积神经网络不仅仅应用于图像相关的网络，还包括与图像相似的网络，例如，在围棋中分析棋盘等。

基本概念

 卷积神经网络中有三个基本的概念：局部感受野（Local Receptive Fields）、共享权值(Shared Weights）、池化（Pooling)。
（1）局部感受野。对于一般的深度神经网络，往往会把图像的每一个像素点连接到全连接的每一个神经元中，而卷积神经网络则是把每一个隐藏节点只连接到图像的某个局部区域，从而减少参数训练的数量。例如，一张1024×720的图像，使用9×9的感受野，则只需要81个权值参数。对于一般的视觉也是如此，当观看一张图像时，更多的时候关注的是局部。
（2）共享权值。在卷积神经网络的卷积层中，神经元对应的权值是相同的，由于权值相同，因此可以减少训练的参数量。共享的权值和偏置也被称作卷积核或滤汲器。
（3）池化。由于待处理的图像往往都比较大，而在实际过程中，没有必要对原图进行分析，能够有效获得图像的特征才是最主要的，因此可以采用类似于图像压缩的思想，对图像进行卷积之后，通过一个下采样过程，来调整图像的大小。

### 主要原理(주요원리)

1. 数据集

Mnist 数据集是一个手写数字图片数据集，数据集的下载和解读详见Mnist数据集解读。这里为了对接pythorch的神经网络，需要将数据集制作成可以批量读取的tensor数据。采用tourch.utils.data.Dataset构建。

Data思路：指定Mnist数据集的存储路径后，根据是否为训练集，找到对应的压缩包，解压文件并读取数据，利用Dataset构建迭代器，从而实现根据索引号返回一组图像和标签的数据。Dataset是一个抽象类，需要继承并重写。其中，根据Mnist数据集文件的命名和存储结构，构建了一个__read_data__私有函数，用来读取数据，返回图像和标签，在__init__中，初始化数据集，获取到原始的数据，在__getitem__中，根据index，返回一组图像和标签，这里可以对图像进行变换，在__len__中返回数据集的样本个数。
为了看懂最后输出的内容，生成了一个实列，取出一组数据，并展示，结果如下：



- 这个项目是我为了重新学习LeNet-5而做的项目（이 프로젝트는 내가 LeNet-5를 다시 공부하기위해서 만든 프로젝트입니다.）
